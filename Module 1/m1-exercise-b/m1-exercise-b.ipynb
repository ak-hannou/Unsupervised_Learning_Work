{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1: Exercise B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will focus on exploratory data analysis of direct marketing campaigns. Let's first load all libraries or packages needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "This dataset is associated with direct marketing campaigns, specifically phone calls, conducted by a banking institution. The classification goal is to predict if a client will subscribe to a term deposit. The variable __y__ represents the outcome of the phone call:\n",
    "\n",
    "- `1` indicates that the client subscribed to a term deposit.\n",
    "- `0` indicates that they did not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 1__\n",
    ">\n",
    ">Import the data file \"bank_marketing.csv\" and check metadata using `info()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 2__\n",
    ">\n",
    ">Check the top 10 rows of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you know which columns contain date information?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The __day__, __month__, and __year__ columns contain date information when clients were reached out to. Let's first convert these columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 3__\n",
    ">\n",
    ">- Combine __day__, __month__, and __year__ columns together to a new datetime column named `last_contact_date`\n",
    ">- Drop three original columns\n",
    ">- Confirm the result by printing its data type and the first 5 rows of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to find out if there's any missing values in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 4__\n",
    ">\n",
    ">- Find the number of missing values in each column\n",
    ">- Retrieve rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like several columns have missing values. What is your suggestion to handle them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 5__\n",
    ">\n",
    ">- Drop missing values in __job__ and __pdays__ as they are small fractions of the data and hard to infer\n",
    ">- Check again the number of missing values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 6__\n",
    ">\n",
    ">- Fill missing values with mean in __balance__\n",
    ">- Retrieve rows with missing values again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've done it properly, you should get 0 rows when retrieving missing values in rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 7__\n",
    ">\n",
    ">Check if there is any duplicates in the data and identify if further action is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the data more. We will dive into a few attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 8__\n",
    ">\n",
    ">Find out how many data points are in each __job__, __marital__, and __poutcome__ category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has many categorical variables, coded as object if it is not specified. The approach to handling categorical variables largely depends on your chosen modeling method. Let's start with columns of __job__, __marital__, and __poutcome__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 9__\n",
    ">\n",
    ">- Convert variables in __job__, __marital__, and __poutcome__ columns into numerical ones (Hint: use `get_dummies` to support dropping the first category in each feature)\n",
    ">- Drop the original columns\n",
    ">- Print the first 5 rows to check the result\n",
    ">\n",
    ">Notes: You may want to consider adding prefix to the values when converting them, e.g., \"job_student\" instead of \"student\", to avoid confusion of category columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's continue with other categorical columns: __default__, __housing__, __loan__. Note that these are binary columns, and you do not need to expand every value into column to fully convert it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 10__\n",
    ">\n",
    ">- Check values and counts in columns: __default__, __housing__, __loan__\n",
    ">- Convert variables into numerical ones\n",
    ">- Drop the original columns\n",
    ">- Print the first 5 rows to check the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have two special columns left, __education__ and __y__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 11__\n",
    ">\n",
    ">- Check values and counts in the __education__ column \n",
    ">- What is the best method to map it to numerical values? Execute your recommended approach and save the encoded data to the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 12__\n",
    ">\n",
    ">Convert __y__ to numeric values and save them to the data frame (Hint: use `LabelEncoder` method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balance usually has long tail, i.e., a small portion of the clients has high bank balance or negative balance. This minority may introduce bias to the model or scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 13__\n",
    ">\n",
    ">Retrieve rows where values are outliers in the __balance__ column\n",
    ">\n",
    ">- Find the the mean and standard deviation of the column\n",
    ">- Create a mask for values less than `mean-3*sd` and greater than `mean+3*sd`\n",
    ">- Use the mask to filter the rows\n",
    ">- Replace outliers with the thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 14__\n",
    ">\n",
    ">Split the data into `X_train`, `X_test`, `y_train`, `y_test` \n",
    ">\n",
    ">- The target variable is __y__, and the remaining columns (except __last_contact_date__) are features\n",
    ">- Set a 80(train):20(test) ratio\n",
    ">- Set 123 randomness and shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 15__\n",
    ">\n",
    ">- Fit `MinMaxScaler` to scale all `X` columns between 0 and 1. Do you need to scale the encoded categorical variables?\n",
    ">- Implement the scaler to both train and test sets from the above task, and save to `X_train_scaled` and `X_test_scaled`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first use pandas default histogram method to plot distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 16__\n",
    ">\n",
    ">Create a line plot to see the number of contact over dates (i.e., __last_contact_date__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 17__\n",
    ">\n",
    ">Create a pie chart of __y__\n",
    ">\n",
    ">Is this balanced or imbalanced? What is the implication of your discovery on the choice of evaluation metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 18__\n",
    ">\n",
    ">Create a scatter plot to show the join distribution of __age__ and __balance__ by __education__ (hint: `hue` parameter), using seaborn method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 19__\n",
    ">\n",
    ">Create a pairplot using seaborn to compare features: __education__, __balance__, __duration__, __campaign__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
